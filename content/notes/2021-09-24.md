+++
title = "2021-09-24"
author = ["Leobardo Argüelles"]
draft = false
+++

## TRANSPUESTA Y MATRICES DE PERMUTACION {#transpuesta-y-matrices-de-permutacion}


### Transpuesta {#transpuesta}

Dice Mr. Hirales que nos ayuda a reducir la cantidad de espacio requerido
para almacenar la informacion.

La matriz transpuesta de A, se denota como \\(A^{T}\\).
Y la transpuesta es la matriz donde las lineas y las columnas estan
volteadas.
E.g:

\begin{equation\*}
A=
\begin{bmatrix}
1\ 2\ 3\\\\
4\ 5\ 6\\\\
\end{bmatrix}
\end{equation\*}

\begin{equation\*}
A^{T} =
\begin{bmatrix}
1\ 4\\\\
2\ 5\\\\
3\ 6\\\\
\end{bmatrix}
\end{equation\*}


#### En numpy {#en-numpy}

La transpuesta es un atributo ya dado en nuestra matriz.
Se accede con:

```python
import numpy as np
A = np.array([[1,2,3],[4,5,6]])
# Esta de abajo sera la transpuesta
return A.T
```


#### U y L {#u-y-l}

L es la matriz triangular inferior, y es la transpuesta de U.
(Pero solo si A es simétrica)

\begin{equation\*}
L = U^{T}
\end{equation\*}


#### Operaciones sobre la trnspuesta {#operaciones-sobre-la-trnspuesta}

<!--list-separator-->

-  Suma

    \begin{equation\*}
    \left( A + B \right)^{T} = A^{T} + B^{T}
    \end{equation\*}

<!--list-separator-->

-  Producto (analisis)

    Se invierte el orden del producto. Checa:

    \begin{equation\*}
    \left( ABC \right)^{T} = C^{T} B^{T} A^{T}
    \end{equation\*}

<!--list-separator-->

-  Inversa

    \begin{equation\*}
    \left( A^{-1} \right)^{T} = \left( A^{T} \right)^{-1}
    \end{equation\*}


#### Redefinición del producto punto {#redefinición-del-producto-punto}

Antes, el producto punto se definia como: \\(x \cdot y\\).
Ahora que conocemos la transpuesta, podemos redefinirlo usando su
concepto.

-   T en la parte interna: \\(x^Ty\\) equivale al producto (1xn)(nx1) = escalar
    Esto es igual que el producto punto.

-   T en la parte externa: \\(xy^T\\) equivale al producto (nx1)(1xn) = matriz


#### Transpuesta de A = LDU {#transpuesta-de-a-ldu}

\begin{equation\*}
A=LDU \\; y \\; A^{T} = U^{T}D^{T}L^{T}
\end{equation\*}


#### Matriz simetrica {#matriz-simetrica}

Es una matriz donde aplicarle la transpuesta no genera ningun cambio.

\begin{equation\*}
A = A^{T}
\end{equation\*}

E.g

\begin{equation\*}
A=
\begin{bmatrix}
1\ 7\ 3\\\\
7\ 4\ 5\\\\
3\ 5\ 0\\\\
\end{bmatrix}
\end{equation\*}

\begin{equation\*}
A^{T}=
\begin{bmatrix}
1\ 7\ 3\\\\
7\ 4\ 5\\\\
3\ 5\ 0\\\\
\end{bmatrix}
\end{equation\*}


#### Transpuesta de una matriz diagonal {#transpuesta-de-una-matriz-diagonal}

\\(D^{T}=D\\)


#### Propiedades interesantes {#propiedades-interesantes}

<!--list-separator-->

-  Matriz rectangular a cuadrada y simetrica

    Si A es una matriz rectangular de (nxm), \\(A^{T}A\\) va ser una matriz
    cuadrada, pues quedará un producto (mxn)(nxm), con un resultado
    de dimensiones (mxm).

    Además, los productos \\(A^{T}A\\) y \\(AA^{T}\\) genera una matriz simetria.
    Por si fuera poco, **la diagonal siempre sera positiva**.

    Por ejemplo:
    EJEMPLO AQUI


#### Factorizacion de matrices simetricas {#factorizacion-de-matrices-simetricas}

Si \\(S=S^{T}\\) (es simetrica), y tenemos su factorizacion \\(LDU\\), sin
intercambiar lineas, entonces \\(U=L^{T}\\).

E.g.

\begin{equation\*}
S=S^{T}
\begin{bmatrix}
1\ 2\\\ 2\ 7\\\\
\end{bmatrix}
\end{equation\*}

Entonces, la factorización \\(A=LDU\\) puede expresarse, **ahorrando espacio**,
como \\(A=LDL^{T}\\).
Se ahorra espacio porque se omite almacenar la matriz U.

Note que:

\begin{equation\*}
\left( LDL^{T} \right)^{T} = (L^{T})^T D^T L^T = LDL^T
\end{equation\*}


### Permutacion {#permutacion}

-   Una matriz \\(P\_{ij\\) es la matris identidad con las lineas i y j intercambiadas.
-   Existen \\(n!\\) permutaciones de orden n.
-   Propiedad importante: \\(P^{-1} = P^{T}\\), por lo que \\(PP^{T}=I\\)


#### Utilidad de permutacion para poder aplicar eliminacion {#utilidad-de-permutacion-para-poder-aplicar-eliminacion}

La factorización A=LU no siempre jala a la primera, porque puede que
haya ceros en la diagonal (que son nuestros pivotes).

Para resolverlo, se aplica una matriz permutacion a A:

\begin{equation\*}
PA = LU
\end{equation\*}

Tomando en cuenta ahora la permutacion, para ciertos casos maybe
aplica machin hacer permutaciones durante la eliminacion
para mejorar la eficiencia o esas madres.
Esto significa que, si antes:

\begin{equation\*}
L=E^{-1}
\end{equation\*}

Ahora puede que esten mezclados los productos de matrices elementales
y de permutacion:

\begin{equation\*}
L=E^{-1}P^{-1} \dots P^{-1}E^{-1}
\end{equation\*}

El orden de esta^ secuencia depende de cada caso particular, y qué
tipo de operacions se realizaron durante el proceso de eliminacion.
